
# ğŸ¡ Advanced Regression - House Price Prediction

## ğŸš€ Competition Summary
This project is part of the **Advanced Regression House Prices** Kaggle competition, where the goal is to predict house prices based on various features using advanced regression techniques.

## ğŸ† My Approach
After watching multiple regression tutorials and experimenting with various techniques, I refined my approach to achieve a **Top 500 Rank on Kaggle**. Below are the key steps taken to improve the model's performance:

### ğŸ“Œ Model Selection
I experimented with several powerful regressors:
- **CatBoost Regressor**
- **XGBoost Regressor**

### ğŸ”„ Pipeline Implementation
To streamline the workflow, I used **sklearnâ€™s Pipeline** to:
- Standardize the data preprocessing steps.
- Ensure consistency in training and testing.
- Reduce the chances of data leakage.

### ğŸ¯ Hyperparameter Tuning
- Used **GridSearchCV** to find the best hyperparameters for optimal model performance.
- Although **Random Search** could have been used, the need was to achieve the **best hyperparameter values**, making **Grid Search** the preferred choice.

---

## ğŸ“Š Submission Performance
I iterated through multiple methods and approaches, improving my model progressively.

### ğŸ”¹ Initial Submissions
<img width="1269" alt="image" src="https://github.com/user-attachments/assets/f536a793-b7c2-40ab-89f7-bf17e0038a35" />

### ğŸ”¹ Latest Submission (Top 500 Rank)
<img width="1221" alt="image" src="https://github.com/user-attachments/assets/0e9dba08-03b0-4a6d-9579-9c9f9acf005a" />

---

## ğŸ” Key Learnings & Next Steps
âœ”ï¸ The impact of hyperparameter tuning on model performance.  
âœ”ï¸ Feature engineering and selection strategies.  
âœ”ï¸ Importance of trying different models and validation techniques.  
âœ”ï¸ Implementing **pipelines** to ensure clean, structured, and efficient model training.

ğŸ”œ **Future Improvements:**
- Experimenting with **Stacking Regressor** for better ensemble learning.
- Fine-tuning features with **feature selection techniques**.
- Exploring **Bayesian Optimization (Optuna) for faster hyperparameter tuning**.

---

ğŸ’¡ **Kaggle Profile:** Rohan Singh08080 
ğŸ“Œ **Repository:**(https://github.com/Roahn333singh)
